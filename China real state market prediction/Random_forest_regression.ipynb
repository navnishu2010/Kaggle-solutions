{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d3821f-362b-4bcb-821b-53017f980927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3d361-47a8-4158-a6e3-0ee2cc820933",
   "metadata": {},
   "source": [
    "#### Loading csv file\n",
    "Some code functions are taken from the https://www.kaggle.com/code/muhammadqasimshabbir/50sec-runtime-gpu-based-real-estate-demand. It was very helpful in doing the feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53572cc-55a4-4a2c-85fb-7ec2f6302c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \"\"\"Load all datasets with optimized memory usage\"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    # Main datasets\n",
    "    datasets = {\n",
    "        'new': 'data/train/new_house_transactions.csv',\n",
    "        'new_nb': 'data/train/new_house_transactions_nearby_sectors.csv',\n",
    "        'pre': 'data/train/pre_owned_house_transactions.csv',\n",
    "        'pre_nb': 'data/train/pre_owned_house_transactions_nearby_sectors.csv',\n",
    "        'land': 'data/train/land_transactions.csv',\n",
    "        'land_nb': 'data/train/land_transactions_nearby_sectors.csv',\n",
    "        'city_idx': 'data/train/city_indexes.csv',\n",
    "        'city_search': 'data/train/city_search_index.csv',\n",
    "        'poi': 'data/train/sector_POI.csv',\n",
    "        'test': 'data/test.csv'\n",
    "    }\n",
    "    \n",
    "    for name, path in datasets.items():\n",
    "        try:\n",
    "            data[name] = pd.read_csv(path)\n",
    "            print(f\"Loaded {name}: {data[name].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {name}: {e}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d05959-d0eb-4ddd-baa8-4e2a89305613",
   "metadata": {},
   "source": [
    "#### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8d502548-41a9-4678-bd9e-3892c253cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datetime_features(df, date_col='month'):\n",
    "    \"\"\"\n",
    "    Extract essential datetime features\n",
    "    \"\"\"\n",
    "    if date_col in df.columns:\n",
    "        # Parse to datetime directly (no splitting needed)\n",
    "        df['date'] = pd.to_datetime(df[date_col], format='%Y-%b')  # e.g. \"2021-Jan\"\n",
    "        df['Year'] = df['date'].dt.year\n",
    "        df['Month_num'] = df['date'].dt.month\n",
    "        df['time_index'] = (df['Year'] - df['Year'].min()) * 12 + df['Month_num']\n",
    "        \n",
    "        # Seasonality encoding\n",
    "        df['sin_month'] = np.sin(2 * np.pi * df['Month_num'] / 12)\n",
    "        df['cos_month'] = np.cos(2 * np.pi * df['Month_num'] / 12)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_sector_features(df, col='sector'):\n",
    "    \"\"\"\n",
    "    Extract numeric sector id from 'sector %d' strings\n",
    "    \"\"\"\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.extract(r'(\\d+)').astype(int)\n",
    "    return df\n",
    "\n",
    "def extract_keyword(df, col='keyword'):\n",
    "    \"\"\"\n",
    "    Extracts the keywords and maps them into integers\n",
    "    \"\"\"\n",
    "    keyword_dict = {'买房':1, '二手房市场':2, '公积金':3, '利率上调':4, '去库存':5, '取消限购':6, '契税':7,\n",
    "                    '学区房':8, '安置':9, '房产税':10, '房价':11, '房价上涨':12, '房价下跌':13, '房价调控':14,\n",
    "                    '房价走势':15, '房地产开发':16, '房地产税':17, '房屋装修':18, '房贷':19, '棚户区':20,\n",
    "                    '棚户区改造':21, '租购':22, '税费':23, '落户':24, '融资':25, '购房':26, '贷款利率':27,\n",
    "                    '限售':28, '限购':29, '首付':30}\n",
    "    \n",
    "    if col in df.columns:\n",
    "        df[col] =  df[col].map(keyword_dict)\n",
    "    return(df)\n",
    "\n",
    "def extract_source(df, col='source'):\n",
    "    \"\"\"\n",
    "    Extracts the source of the keyword search and maps into integers\n",
    "    \"\"\"\n",
    "\n",
    "    keyword_dict = {'PC端':1, '移动端':2}\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(keyword_dict)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d9398a66-b48a-4a69-8ad4-192f63be07ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded new: (5433, 11)\n",
      "Loaded new_nb: (5360, 11)\n",
      "Loaded pre: (5360, 6)\n",
      "Loaded pre_nb: (5427, 6)\n",
      "Loaded land: (5896, 6)\n",
      "Loaded land_nb: (5025, 6)\n",
      "Loaded city_idx: (7, 74)\n",
      "Loaded city_search: (4020, 4)\n",
      "Loaded poi: (86, 142)\n",
      "Loaded test: (1152, 2)\n",
      "last row was removed from city_indexes files as it was a copy\n",
      "268\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "all_data = load_all_data()\n",
    "all_data['city_idx'] = all_data['city_idx'].iloc[:-1]\n",
    "print(\"last row was removed from city_indexes files as it was a copy\")\n",
    "dfname_key = list(all_data.keys())\n",
    "\n",
    "\n",
    "for key in dfname_key:\n",
    "    #all_data[key] = extract_datetime_features(all_data[key], date_col='month')\n",
    "    all_data[key] = extract_sector_features(all_data[key], col='sector')\n",
    "    all_data[key] = extract_keyword(all_data[key], col='keyword')\n",
    "    all_data[key] = extract_source(all_data[key], col='source')\n",
    "\n",
    "#Unique features from all data files\n",
    "all_features = []\n",
    "for key in dfname_key:\n",
    "    temp_keys = all_data[key].keys()\n",
    "    all_features.extend(temp_keys)\n",
    "\n",
    "print(len(all_features))\n",
    "all_features = set(all_features)\n",
    "all_features = list(all_features)\n",
    "print(len(all_features) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541f79c-c02a-40ef-aa41-ac9efb7f0730",
   "metadata": {},
   "source": [
    "#### MERGING THE DATA FRAMES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5567ea8c-6769-4573-ba96-f3ebbb74886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_features(df, date_col='month'):\n",
    "    \"\"\"\n",
    "    Extract year features\n",
    "    \"\"\"\n",
    "    if date_col in df.columns:\n",
    "        # Parse to datetime directly (no splitting needed)\n",
    "        df[\"year\"] = df[date_col].str.split(\"-\").str[0].astype(int)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1b659780-f944-45d3-a583-73b9d723b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5433, 20)\n",
      "(5433, 24)\n",
      "(5433, 28)\n",
      "(5433, 32)\n",
      "(5433, 36)\n",
      "(5433, 177)\n",
      "(325980, 180)\n",
      "(325980, 181)\n",
      "[2019 2020 2021 2022 2023 2024]\n",
      "(325980, 254)\n",
      "[2019 2020 2021 2022 2023 2024]\n",
      "No string in the data!! Proceed further for training\n"
     ]
    }
   ],
   "source": [
    "superdata = pd.merge(all_data['new'], all_data['new_nb'], on=[\"sector\", \"month\"], how=\"left\")\n",
    "print(superdata.shape)\n",
    "\n",
    "superdata = pd.merge(superdata, all_data['pre'], on=[\"sector\", \"month\"], how=\"left\")\n",
    "print(superdata.shape)\n",
    "\n",
    "superdata = pd.merge(superdata, all_data['pre_nb'], on=[\"sector\", \"month\"], how=\"left\")\n",
    "print(superdata.shape)\n",
    "\n",
    "superdata = pd.merge(superdata, all_data['land'], on=[\"sector\", \"month\"], how=\"left\")\n",
    "print(superdata.shape)\n",
    "\n",
    "superdata = pd.merge(superdata, all_data['land_nb'], on=[\"sector\", \"month\"], how=\"left\")\n",
    "print(superdata.shape)\n",
    "\n",
    "superdata = pd.merge(superdata, all_data['poi'], on=[\"sector\"], how=\"left\")\n",
    "print(superdata.shape)\n",
    "\n",
    "superdata = pd.merge(superdata, all_data['city_search'], on=[\"month\"], how=\"left\")\n",
    "print(superdata.shape)\n",
    "\n",
    "#NOTICE THE SHAPE CHANGE OF THE SUPER DATA SET HERE\n",
    "superdata = extract_year_features(superdata, date_col='month')\n",
    "print(superdata.shape)\n",
    "print(superdata['year'].unique())\n",
    "\n",
    "#Changing the feature name to year of the city(not sector)\n",
    "all_data['city_idx'].rename(columns={'city_indicator_data_year': 'year'}, inplace=True)\n",
    "superdata = pd.merge(superdata, all_data['city_idx'], on=[\"year\"], how=\"left\")\n",
    "print(superdata.shape)\n",
    "print(superdata['year'].unique())\n",
    "\n",
    "#Filling NaN with 0 in the entire data frame\n",
    "superdata = superdata.fillna(0)\n",
    "superdata = extract_datetime_features(superdata, date_col='month')\n",
    "\n",
    "superdata.drop('Year', axis=1, inplace=True)\n",
    "superdata.drop('month', axis=1, inplace=True)\n",
    "first_row = superdata.iloc[0]\n",
    "\n",
    "#CHECKING FOR THE FEATURES HAVE STRING ENTRIES\n",
    "string_check = 0\n",
    "for col, value in first_row.items():\n",
    "    if isinstance(value, str):\n",
    "        print(col, isinstance(value, str))\n",
    "        string_check = 1\n",
    "\n",
    "if string_check==0:\n",
    "    print(\"No string in the data!! Proceed further for training\")\n",
    "else:\n",
    "    print(\"Data not ready for training\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6b84b963-22fa-4c34-a00d-1133cb9ce91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019 2020 2021 2022 2023 2024]\n"
     ]
    }
   ],
   "source": [
    "print(superdata['year'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e6768-45b1-476c-bf9b-51d9fb194794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b742bc4-2703-4c3c-8787-3f7eae0b03d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d887b-bb8d-4f1c-a909-f2534760e745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b31a37-1fcc-46cc-8fd1-e9e3987c6951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9243036-2e7d-4aae-81e9-9d35f13b087a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb1e74-1315-49ea-a4f3-aff6198c8f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34dbe4-b970-427c-8549-e3820b992c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adfc583-f919-4ed7-bb95-79a5685b7c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998984f-85c3-4211-89f4-8f76e3af6ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
